{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pymilvus import connections, db\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP-1 Prepare Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../documents.json') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_name = data[0]['course']\n",
    "i = 1\n",
    "for document in data[0]['documents']:\n",
    "    document['document_id'] = i\n",
    "    document['course'] = course_name\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = data[0]['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as f_out:\n",
    "    json.dump(json_data, f_out) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Ground Truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAI_KEY = os.getenv(\"OPEN_AI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = OpenAI_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groundtruth(data, client):\n",
    "    groundtruth_dataset = []\n",
    "    prompt = \"\"\"\n",
    "        You are a course assistant. Given the following text, generate 5 potential questions that could be asked from the content. Return your response as a JSON array of strings, where each string is a question. Do not include any explanations or additional text outside the JSON structure.\n",
    "\n",
    "        Text: {text_field}\n",
    "\n",
    "        Response format:\n",
    "        [\"Question 1\", \"Question 2\", \"Question 3\", \"Question 4\", \"Question 5\"]\n",
    "        \"\"\"\n",
    "    for json_document in tqdm(data):\n",
    "        try:\n",
    "            text = json_document[\"text\"]\n",
    "            section = json_document[\"section\"]\n",
    "            document_id = json_document[\"document_id\"]\n",
    "            course = json_document[\"course\"]\n",
    "            prompt_injected = prompt.format(text_field = text)\n",
    "            completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt_injected,\n",
    "                }\n",
    "            ],\n",
    "                model = 'gpt-4o-mini',\n",
    "            )\n",
    "            response = completion.choices[0].message.content\n",
    "            questions = json.loads(response)\n",
    "            for question in questions:\n",
    "                dictionary = dict()\n",
    "                dictionary[\"text\"] = text\n",
    "                dictionary[\"question\"] = question\n",
    "                dictionary[\"section\"] = section\n",
    "                dictionary[\"document_id\"] = document_id\n",
    "                dictionary[\"course\"] = course\n",
    "                groundtruth_dataset.append(dictionary)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue        \n",
    "    return groundtruth_dataset\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def create_groundtruth(data, client):\n",
    "    groundtruth_dataset = []\n",
    "    prompt = \"\"\"\n",
    "        You are a course assistant. Given the following text, generate 5 potential questions that could be asked from the content. Return your response as a JSON array of strings, where each string is a question. Do not include any explanations or additional text outside the JSON structure.\n",
    "\n",
    "        Text: {text_field}\n",
    "\n",
    "        Response format:\n",
    "        [\"Question 1\", \"Question 2\", \"Question 3\", \"Question 4\", \"Question 5\"]\n",
    "        \"\"\"\n",
    "\n",
    "    @backoff.on_exception(backoff.expo, Exception, max_tries=5)\n",
    "    def make_api_call(prompt_injected):\n",
    "        return client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt_injected,\n",
    "                }\n",
    "            ],\n",
    "            model='gpt-4o-mini',\n",
    "        )\n",
    "\n",
    "    total_documents = len(data)\n",
    "    successful_documents = 0\n",
    "\n",
    "    for i, json_document in enumerate(tqdm(data, desc=\"Processing documents\")):\n",
    "        try:\n",
    "            text = json_document[\"text\"]\n",
    "            section = json_document[\"section\"]\n",
    "            document_id = json_document[\"document_id\"]\n",
    "            course = json_document[\"course\"]\n",
    "            prompt_injected = prompt.format(text_field=text)\n",
    "\n",
    "            completion = make_api_call(prompt_injected)\n",
    "            response = completion.choices[0].message.content\n",
    "            questions = json.loads(response)\n",
    "\n",
    "            for question in questions:\n",
    "                dictionary = {\n",
    "                    \"text\": text,\n",
    "                    \"question\": question,\n",
    "                    \"section\": section,\n",
    "                    \"document_id\": document_id,\n",
    "                    \"course\": course\n",
    "                }\n",
    "                groundtruth_dataset.append(dictionary)\n",
    "\n",
    "            successful_documents += 1\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parsing error in document {i}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing document {i}: {e}\")\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Processed {i + 1}/{total_documents} documents. Successful: {successful_documents}\")\n",
    "            time.sleep(75)\n",
    "    print(f\"Finished processing. Total documents: {total_documents}, Successful: {successful_documents}\")\n",
    "    return groundtruth_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:   2%|▏         | 9/435 [00:18<15:20,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/435 documents. Successful: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:   4%|▍         | 19/435 [01:59<19:06,  2.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20/435 documents. Successful: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:   7%|▋         | 29/435 [03:30<16:51,  2.49s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 30/435 documents. Successful: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:   9%|▉         | 39/435 [05:01<16:37,  2.52s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 40/435 documents. Successful: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  11%|█▏        | 49/435 [06:36<18:28,  2.87s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50/435 documents. Successful: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  14%|█▎        | 59/435 [08:11<17:31,  2.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 60/435 documents. Successful: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  15%|█▍        | 64/435 [09:34<45:34,  7.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing error in document 63: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  15%|█▍        | 65/435 [09:37<36:14,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing error in document 64: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  16%|█▌        | 69/435 [09:44<17:06,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 70/435 documents. Successful: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  18%|█▊        | 79/435 [11:15<14:54,  2.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 80/435 documents. Successful: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  20%|██        | 89/435 [12:46<14:25,  2.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 90/435 documents. Successful: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  21%|██        | 91/435 [14:04<1:42:13, 17.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing error in document 90: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  23%|██▎       | 99/435 [14:18<15:05,  2.69s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100/435 documents. Successful: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  25%|██▌       | 109/435 [15:48<12:46,  2.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 110/435 documents. Successful: 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  27%|██▋       | 119/435 [17:19<13:36,  2.58s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 120/435 documents. Successful: 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  30%|██▉       | 129/435 [18:49<12:44,  2.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 130/435 documents. Successful: 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  32%|███▏      | 139/435 [20:19<11:24,  2.31s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 140/435 documents. Successful: 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  34%|███▎      | 146/435 [21:44<19:36,  4.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing error in document 145: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  34%|███▍      | 149/435 [21:48<10:42,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 150/435 documents. Successful: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  37%|███▋      | 159/435 [23:20<11:29,  2.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 160/435 documents. Successful: 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  39%|███▉      | 169/435 [24:49<11:05,  2.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 170/435 documents. Successful: 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  41%|████      | 179/435 [26:26<12:36,  2.96s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 180/435 documents. Successful: 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  43%|████▎     | 189/435 [27:56<09:34,  2.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing error in document 189: Expecting value: line 1 column 1 (char 0)\n",
      "Processed 190/435 documents. Successful: 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  46%|████▌     | 199/435 [29:27<09:35,  2.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200/435 documents. Successful: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  48%|████▊     | 209/435 [30:56<08:56,  2.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 210/435 documents. Successful: 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  50%|█████     | 219/435 [32:27<08:56,  2.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 220/435 documents. Successful: 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  52%|█████▏    | 226/435 [33:53<14:27,  4.15s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing error in document 225: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  53%|█████▎    | 229/435 [33:58<08:18,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 230/435 documents. Successful: 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  55%|█████▍    | 239/435 [35:26<07:17,  2.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 240/435 documents. Successful: 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  57%|█████▋    | 249/435 [36:53<07:24,  2.39s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 250/435 documents. Successful: 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  60%|█████▉    | 259/435 [38:21<05:56,  2.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 260/435 documents. Successful: 254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  62%|██████▏   | 269/435 [39:54<07:46,  2.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 270/435 documents. Successful: 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  64%|██████▍   | 279/435 [41:23<05:32,  2.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 280/435 documents. Successful: 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  66%|██████▋   | 289/435 [42:53<05:46,  2.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 290/435 documents. Successful: 284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  69%|██████▊   | 299/435 [44:21<04:58,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 300/435 documents. Successful: 294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  71%|███████   | 309/435 [45:50<04:48,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 310/435 documents. Successful: 304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  73%|███████▎  | 319/435 [47:16<04:13,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 320/435 documents. Successful: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  74%|███████▍  | 321/435 [48:34<33:09, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing error in document 320: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  76%|███████▌  | 329/435 [48:44<03:45,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 330/435 documents. Successful: 323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  78%|███████▊  | 339/435 [50:12<03:36,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 340/435 documents. Successful: 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  80%|████████  | 349/435 [51:41<03:27,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 350/435 documents. Successful: 343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  81%|████████▏ | 354/435 [53:03<09:20,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing error in document 353: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  83%|████████▎ | 359/435 [53:09<02:49,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 360/435 documents. Successful: 352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  85%|████████▍ | 369/435 [54:41<02:52,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 370/435 documents. Successful: 362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  87%|████████▋ | 379/435 [56:16<02:36,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 380/435 documents. Successful: 372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  89%|████████▉ | 389/435 [57:48<02:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 390/435 documents. Successful: 382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  92%|█████████▏| 399/435 [59:24<01:35,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 400/435 documents. Successful: 392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  94%|█████████▍| 409/435 [1:00:59<01:17,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 410/435 documents. Successful: 402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  96%|█████████▌| 416/435 [1:02:25<01:24,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing error in document 415: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  96%|█████████▋| 419/435 [1:02:30<00:42,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 420/435 documents. Successful: 411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:  99%|█████████▊| 429/435 [1:04:05<00:17,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 430/435 documents. Successful: 421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|█████████▉| 434/435 [1:05:30<00:07,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parsing error in document 433: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 435/435 [1:05:32<00:00,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing. Total documents: 435, Successful: 425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "groundtruth_dataset = create_groundtruth(json_data, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('groundtruth_dataset.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(groundtruth_dataset, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 - Create Embeddings using Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.1, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"dunzhang/stella_en_1.5B_v5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model.encode(\"This is a test\")\n",
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/435 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [2:56:12<00:00, 24.31s/it]  \n"
     ]
    }
   ],
   "source": [
    "operations = []\n",
    "for doc in tqdm(json_data):\n",
    "    doc[\"text_vector\"] = model.encode(doc[\"text\"]).tolist()\n",
    "    operations.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('operations.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(operations, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Elastic Search Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'baae846d5e1f', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'h2iYJMQHQouhleDTcCFGtA', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\" : {\n",
    "        \"number_of_shards\" : 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"text_vector\": {\"type\": \"dense_vector\", \"dims\": 1024, \"index\" :True, \"similarity\": \"cosine\"},\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"course-questions\"\n",
    "\n",
    "es.indices.delete(index= index_name, ignore_unavailable=True)\n",
    "es.indices.create(index= index_name, body= index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in operations:\n",
    "    try:\n",
    "        es.index(index= index_name, body= doc)\n",
    "    except Exception as e:\n",
    "        print(f\"Error is {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"windows or mac?\"\n",
    "vector_query = model.encode(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = {\n",
    "    \"field\" : \"text_vector\",\n",
    "    \"query_vector\": vector_query,\n",
    "    \"k\": 5,\n",
    "    \"num_candidates\": 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = es.search(index=index_name, knn=ques, source=[\"text\", \"section\", \"question\", \"course\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = res[\"hits\"][\"hits\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('_index', 'course-questions'), ('_id', 'BENg8ZABRJ5_F5RWVrGj'), ('_score', 0.9188564), ('_source', {'question': 'When configuring the profiles.yml file for dbt-postgres with jinja templates with environment variables, I\\'m getting \"Credentials in profile \"PROFILE_NAME\", target: \\'dev\\', invalid: \\'5432\\'is not of type \\'integer\\'', 'course': 'data-engineering-zoomcamp', 'section': 'Module 5: pyspark', 'text': 'Update the line:\\nWith:'})])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milvus Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connections.connect(host=\"127.0.0.1\", port=19530)\n",
    "\n",
    "database = db.create_database(\"my_database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.using_database(\"my_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import FieldSchema, CollectionSchema, DataType\n",
    "\n",
    "id_field = FieldSchema(name=\"document_id\", dtype=DataType.INT64, is_primary=True, description=\"primary id\")\n",
    "text_field = FieldSchema(name='text', dtype= DataType.VARCHAR)\n",
    "question_field = FieldSchema(name='question', dtype= DataType.VARCHAR)\n",
    "course_field = FieldSchema(name='course', dtype= DataType.VARCHAR)\n",
    "\n",
    "embedding_field = FieldSchema(name=\"text_vector\", dtype=DataType.FLOAT_VECTOR, dim=1024, description=\"vector\")\n",
    "\n",
    "\n",
    "schema = CollectionSchema(fields=[id_field, text_field, question_field, course_field, embedding_field], auto_id=False, enable_dynamic_field=True, description=\"desc of a collection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, DataType\n",
    "\n",
    "# 1. Set up a Milvus client\n",
    "client = MilvusClient(\n",
    "    uri=\"http://localhost:19530\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python envm",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
